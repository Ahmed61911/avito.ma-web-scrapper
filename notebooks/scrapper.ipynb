{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2376c3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import numpy as np\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5845300e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m     LINK = LISTING.get(\u001b[33m\"\u001b[39m\u001b[33mhref\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m LISTING \u001b[38;5;129;01mand\u001b[39;00m LISTING.get(\u001b[33m\"\u001b[39m\u001b[33mhref\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mN/A\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     15\u001b[39m     LINKS = np.append(LINKS, LINK)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.8\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "LINKS = []\n",
    "#Number of pages we want to scrape\n",
    "PAGES = 40    \n",
    "\n",
    "# Itterating over the pages\n",
    "for PAGE in range(1, PAGES + 1):\n",
    "    TARGET_URL = f'https://www.avito.ma/fr/maroc/voitures?o={PAGE}'\n",
    "    HEADERS = {'user-agent' : \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/144.0.0.0 Safari/537.36\"}\n",
    "    RESPONSE = requests.get(TARGET_URL, headers=HEADERS)\n",
    "    PAGE_CONTENT = bs(RESPONSE.content, \"html.parser\")\n",
    "    LISTINGS = PAGE_CONTENT.find_all(\"a\", class_=\"sc-1jge648-0\")\n",
    "    # Getting the link of each listing and append it to out listings list\n",
    "    for LISTING in LISTINGS:\n",
    "        LINK = LISTING.get(\"href\") if LISTING and LISTING.get(\"href\") else \"N/A\"\n",
    "        LINKS = np.append(LINKS, LINK)\n",
    "    time.sleep(0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4c9c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping duplicat links\n",
    "link_sr = pd.Series(LINKS)\n",
    "link_sr = link_sr.drop_duplicates().reset_index(drop=True)\n",
    "link_sr.value_counts()\n",
    "# Array of links\n",
    "links = np.array(link_sr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4456c563",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings = []\n",
    "headers = {\"user-agent\": (\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/144.0.0.0 Safari/537.36\")}\n",
    "#Itterating over the links we got\n",
    "for link in links:\n",
    "    response = requests.get(link, headers=headers, timeout=10)\n",
    "    page = bs(response.content, \"html.parser\")\n",
    "\n",
    "    # Link\n",
    "    listing = {\"lien\": link}\n",
    "\n",
    "    # Listing title\n",
    "    title = page.find(\"h1\", class_=\"sc-16573058-5 izVEJU\")\n",
    "    listing[\"titre_annonce\"] = title.text.strip() if title else None\n",
    "\n",
    "    # Price\n",
    "    price = page.find(\"div\", class_=\"sc-16573058-10 kRLGQQ\")\n",
    "    listing[\"prix\"] = price.text.strip() if price else None\n",
    "\n",
    "    # Address & date\n",
    "    spans = page.find_all(\"span\", class_=\"sc-16573058-17 gLkxLA\")\n",
    "    listing[\"spans\"] = [span.text.strip() for span in spans] if spans else None\n",
    "\n",
    "    # Owner\n",
    "    owner = page.find(\"p\",class_=\"sc-1x0vz2r-0 fUTtTl sc-1l0do2b-9 bJuYLD\")\n",
    "    listing[\"proprietere\"] = owner.text.strip() if owner else None\n",
    "\n",
    "    # Tags\n",
    "    spans = page.find_all(\"span\", class_=\"sc-1x0vz2r-0 fjZBup\")\n",
    "    listing[\"tags\"] = [span.text.strip() for span in spans] if spans else None\n",
    "    # Images\n",
    "    listing[\"images\"] = [img.get(\"src\") for img in page.find_all(\"img\", class_=\"sc-1gjavk-0 fpXQoT\") if img.get(\"src\")] if page.find_all(\"img\", class_=\"sc-1gjavk-0 fpXQoT\") else None\n",
    "    \n",
    "    # Append listing to listings array\n",
    "    listings.append(listing)\n",
    "\n",
    "    # Waiting a bit so we dont get banned\n",
    "    time.sleep(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdec2853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# price cleaning\n",
    "def clean_price(x):\n",
    "    # Remove anything that is not a digit\n",
    "    x = re.sub(r\"[^\\d]\", \"\", x)\n",
    "    return int(x) if x.isdigit() else None\n",
    "\n",
    "# Mileage cleaning\n",
    "def clean_mileage(tags):\n",
    "    if not tags or len(tags) <= 4:\n",
    "        return np.nan\n",
    "    val = tags[4].strip().lower()\n",
    "    val = re.sub(r\"[^\\d]\", \"\", val)\n",
    "    return int(val) if val.isdigit() else np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0ba1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.DataFrame(listings)\n",
    "df_clean = df_raw.copy()\n",
    "\n",
    "# Dividing 'spans' column into 'ville', 'quartier', 'date'\n",
    "df_clean[\"ville\"] = df_clean[\"spans\"].apply(lambda x: x[0].split(\",\")[1].strip().lower() if len(x) > 0 and len(x[0].split(\",\")) > 1 else None)\n",
    "df_clean[\"quartier\"] = df_clean[\"spans\"].apply(lambda x: x[0].split(\",\")[0].strip().lower() if len(x) > 0 else None)\n",
    "df_clean['date'] = df_clean['spans'].apply(lambda x : x[1].lstrip(\"il y a \").lower() if len(x) > 1 else None)\n",
    "\n",
    "# cleaning price Column\n",
    "df_clean['prix'] = df_clean['prix'].apply(clean_price)\n",
    "\n",
    "# Dividing 'tags' column into 'category', 'annee', 'transsmission', 'carburant', 'kilometrage', 'marque', 'modele', 'equipements'\n",
    "df_clean['category'] = df_clean['tags'].apply(lambda x : x[0].split(\",\")[0].strip().lower() if len(x) > 0 else None)\n",
    "df_clean['type_annonce'] = df_clean['tags'].apply(lambda x : x[0].split(\",\")[1].strip().lower() if len(x) > 0 else None)\n",
    "df_clean['annee'] = df_clean['tags'].apply(lambda x : int(x[1].strip()) if len(x) > 1 else None)\n",
    "df_clean['transmission'] = df_clean['tags'].apply(lambda x : x[2].strip().lower() if len(x) > 2 else None)\n",
    "df_clean['carburant'] = df_clean['tags'].apply(lambda x : x[3].strip().lower() if len(x) > 3 else None)\n",
    "df_clean['kilometrage'] = df_clean['tags'].apply(clean_mileage)\n",
    "df_clean['marque'] = df_clean['tags'].apply(lambda x : x[5].strip().lower() if len(x) > 5 else None)\n",
    "df_clean['modele'] = df_clean['tags'].apply(lambda x : x[6].strip().lower() if len(x) > 6 else None)\n",
    "df_clean['equipements'] = df_clean['tags'].apply(lambda x : [e.strip().lower() for e in x[7:]] if len(x) > 7 else None)\n",
    "\n",
    "# Dropping 'tags' and 'spans' columns \n",
    "df_clean = df_clean.drop(columns=['tags', 'spans'])\n",
    "\n",
    "# Organizing the columns\n",
    "df_clean = df_clean.reset_index(drop=True)\n",
    "df_clean = df_clean[['titre_annonce', 'type_annonce', 'ville' ,'quartier' , 'prix', 'marque', 'modele', 'annee', 'kilometrage', 'carburant', 'transmission', 'equipements', 'date', 'proprietere', 'images', 'lien']]\n",
    "\n",
    "# Saving the fnale result\n",
    "df_clean.to_csv(\"../data/avito_listings.csv\" , index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83cabd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "titre_annonce    108\n",
       "type_annonce     108\n",
       "ville            108\n",
       "quartier         108\n",
       "prix              56\n",
       "marque            96\n",
       "modele            96\n",
       "annee             96\n",
       "kilometrage       96\n",
       "carburant         96\n",
       "transmission      96\n",
       "equipements       79\n",
       "date             108\n",
       "proprietere      108\n",
       "images           108\n",
       "lien             108\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
